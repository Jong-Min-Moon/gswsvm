}
}
best.hyperparameter.index <- arrayInd(which.min(tuning.criterion.values), dim(tuning.criterion.values))
gamma.best <- gamma.set[best.hyperparameter.index[1]]
c.best <- c.set[best.hyperparameter.index[2]]
best.model <- wsvm(y ~ ., weight = L.vector.train, gamma = 1, cost = c.best, kernel="radial", scale = FALSE, data = data.train)
plot.basic <- draw.basic(data.tune, col.p = "blue", col.n = "red", alpha.p = 0.3, alpha.n = 0.3)
plot.bayes <-draw.bayes.rule(data.train, p.mus, n.mus, p.sigma, n.sigma, imbalance.ratio.s, cost.ratio)
plot.wsvm <- draw.svm.rule(data.train, best.model)
plot.basic + plot.bayes + plot.wsvm
library(WeightSVM)
source("data_generator.R")
source("bayes_rule.R")
#cost ratio
c.neg = 4
c.pos = 1
cost.ratio = c.neg/c.pos
#real imbalance ratio
imbalance.ratio = 4
pi.pos = 1/(1+imbalance.ratio)
pi.neg = 1 - pi.pos
#sampling imbalance ratio
pi.s.pos = 0.3
pi.s.neg = 1 - pi.s.pos
imbalance.ratio.s =  pi.s.neg / pi.s.pos
L.pos = c.neg * pi.s.neg * pi.pos
L.neg = c.pos * pi.s.pos * pi.neg
#data generation
n.sample = 2e3
#checkerboard data
p.mean1 <- c(-7,-5);
p.mean2 <- c(3,-5);
p.mean3 <- c(-2,0);
p.mean4 <- c(8,0);
p.mean5 <- c(-7,5);
p.mean6 <- c(2,5);
p.mus <- rbind(p.mean1, p.mean2, p.mean3, p.mean4, p.mean5, p.mean6)
p.sigma <- matrix(c(4,0,0,4),2,2)
n.mean1 <- c(-2,-5);
n.mean2 <- c(8,-5);
n.mean3 <- c(-7,0);
n.mean4 <- c(3,0);
n.mean5 <- c(-2,5);
n.mean6 <- c(8,5);
n.mus <- rbind(n.mean1,n.mean2,n.mean3,n.mean4, n.mean5, n.mean6)
n.sigma <- matrix(c(6,0,0,6.5),2,2)
#generate dataset
data = generate.mvn.mixture(p.mus, n.mus, p.sigma, n.sigma, imbalance.ratio = imbalance.ratio.s, n.sample = n.sample)
#split the dataset into training set and tuning set
indices.pos = (1:n.sample)[data$y == "pos"]
indices.pos.train = sample(indices.pos, length(indices.pos)/2)
indices.neg = (1:n.sample)[data$y == "neg"]
indices.neg.train = sample(indices.neg, length(indices.neg)/2)
indices.train = sort(c(indices.pos.train,indices.neg.train))
data.train = data[indices.train, ]
data.tune = data[-indices.train, ]
y.tune.real = data.tune$y
L.vector.tune = (y.tune.real == "pos") * L.pos + (y.tune.real == "neg") * L.neg
y.train.real = data.train$y
L.vector.train = (y.train.real == "pos") * L.pos + (y.train.real == "neg") * L.neg
#tuning
c.set = 2^(-5 : 5);
gamma.set = 2^(-5 : 5);
tuning.criterion.values = matrix(nrow = length(gamma.set), ncol = length(c.set))
for (i in 1:length(gamma.set)){
for (j in 1:length(c.set)){
gamma.now = gamma.set[i]
c.now = c.set[j]
model.now <- wsvm(y ~ ., weight = L.vector.tune, gamma = gamma.now, cost = c.now, kernel="radial", scale = FALSE, data = data.tune)
y.pred.now <- fitted(model.now) #f(x_i) value
tuning.criterion.values[i,j] <- sum((y.pred.now != y.tune.real) * L.vector.tune)/(n.sample/2)
}
}
best.hyperparameter.index <- arrayInd(which.min(tuning.criterion.values), dim(tuning.criterion.values))
gamma.best <- gamma.set[best.hyperparameter.index[1]]
c.best <- c.set[best.hyperparameter.index[2]]
best.model <- wsvm(y ~ ., weight = L.vector.train, gamma = 1, cost = c.best, kernel="radial", scale = FALSE, data = data.train)
plot.basic <- draw.basic(data.tune, col.p = "blue", col.n = "red", alpha.p = 0.3, alpha.n = 0.3)
plot.bayes <-draw.bayes.rule(data.train, p.mus, n.mus, p.sigma, n.sigma, imbalance.ratio.s, cost.ratio)
plot.wsvm <- draw.svm.rule(data.train, best.model)
plot.basic + plot.bayes + plot.wsvm
library(WeightSVM)
source("data_generator.R")
source("bayes_rule.R")
#cost ratio
c.neg = 4
c.pos = 1
cost.ratio = c.neg/c.pos
#real imbalance ratio
imbalance.ratio = 4
pi.pos = 1/(1+imbalance.ratio)
pi.neg = 1 - pi.pos
#sampling imbalance ratio
pi.s.pos = 0.3
pi.s.neg = 1 - pi.s.pos
imbalance.ratio.s =  pi.s.neg / pi.s.pos
L.pos = c.neg * pi.s.neg * pi.pos
L.neg = c.pos * pi.s.pos * pi.neg
#data generation
n.sample = 2e3
#checkerboard data
p.mean1 <- c(-7,-5);
p.mean2 <- c(3,-5);
p.mean3 <- c(-2,0);
p.mean4 <- c(8,0);
p.mean5 <- c(-7,5);
p.mean6 <- c(2,5);
p.mus <- rbind(p.mean1, p.mean2, p.mean3, p.mean4, p.mean5, p.mean6)
p.sigma <- matrix(c(2,0,0,2),2,2)
n.mean1 <- c(-2,-5);
n.mean2 <- c(8,-5);
n.mean3 <- c(-7,0);
n.mean4 <- c(3,0);
n.mean5 <- c(-2,5);
n.mean6 <- c(8,5);
n.mus <- rbind(n.mean1,n.mean2,n.mean3,n.mean4, n.mean5, n.mean6)
n.sigma <- matrix(c(2.5,0,0,2.5),2,2)
#generate dataset
data = generate.mvn.mixture(p.mus, n.mus, p.sigma, n.sigma, imbalance.ratio = imbalance.ratio.s, n.sample = n.sample)
#split the dataset into training set and tuning set
indices.pos = (1:n.sample)[data$y == "pos"]
indices.pos.train = sample(indices.pos, length(indices.pos)/2)
indices.neg = (1:n.sample)[data$y == "neg"]
indices.neg.train = sample(indices.neg, length(indices.neg)/2)
indices.train = sort(c(indices.pos.train,indices.neg.train))
data.train = data[indices.train, ]
data.tune = data[-indices.train, ]
y.tune.real = data.tune$y
L.vector.tune = (y.tune.real == "pos") * L.pos + (y.tune.real == "neg") * L.neg
y.train.real = data.train$y
L.vector.train = (y.train.real == "pos") * L.pos + (y.train.real == "neg") * L.neg
#tuning
c.set = 2^(-5 : 5);
gamma.set = 2^(-5 : 5);
tuning.criterion.values = matrix(nrow = length(gamma.set), ncol = length(c.set))
for (i in 1:length(gamma.set)){
for (j in 1:length(c.set)){
gamma.now = gamma.set[i]
c.now = c.set[j]
model.now <- wsvm(y ~ ., weight = L.vector.tune, gamma = gamma.now, cost = c.now, kernel="radial", scale = FALSE, data = data.tune)
y.pred.now <- fitted(model.now) #f(x_i) value
tuning.criterion.values[i,j] <- sum((y.pred.now != y.tune.real) * L.vector.tune)/(n.sample/2)
}
}
best.hyperparameter.index <- arrayInd(which.min(tuning.criterion.values), dim(tuning.criterion.values))
gamma.best <- gamma.set[best.hyperparameter.index[1]]
c.best <- c.set[best.hyperparameter.index[2]]
best.model <- wsvm(y ~ ., weight = L.vector.train, gamma = 1, cost = c.best, kernel="radial", scale = FALSE, data = data.train)
plot.basic <- draw.basic(data.tune, col.p = "blue", col.n = "red", alpha.p = 0.3, alpha.n = 0.3)
plot.bayes <-draw.bayes.rule(data.train, p.mus, n.mus, p.sigma, n.sigma, imbalance.ratio.s, cost.ratio)
plot.wsvm <- draw.svm.rule(data.train, best.model)
plot.basic + plot.bayes + plot.wsvm
floor(2.2)
library(WeightSVM)
source("data_generator.R")
source("bayes_rule.R")
#cost ratio
c.neg = 4
c.pos = 1
cost.ratio = c.neg/c.pos
#real imbalance ratio
imbalance.ratio = 4
pi.pos = 1/(1+imbalance.ratio)
pi.neg = 1 - pi.pos
#sampling imbalance ratio
pi.s.pos = 0.3
pi.s.neg = 1 - pi.s.pos
imbalance.ratio.s =  pi.s.neg / pi.s.pos
L.pos = c.neg * pi.s.neg * pi.pos
L.neg = c.pos * pi.s.pos * pi.neg
#data generation
n.samples = 1e4
#checkerboard data
p.mean1 <- c(-7,-5);
p.mean2 <- c(3,-5);
p.mean3 <- c(-2,0);
p.mean4 <- c(8,0);
p.mean5 <- c(-7,5);
p.mean6 <- c(2,5);
p.mus <- rbind(p.mean1, p.mean2, p.mean3, p.mean4, p.mean5, p.mean6)
p.sigma <- matrix(c(2,0,0,2),2,2)
n.mean1 <- c(-2,-5);
n.mean2 <- c(8,-5);
n.mean3 <- c(-7,0);
n.mean4 <- c(3,0);
n.mean5 <- c(-2,5);
n.mean6 <- c(8,5);
n.mus <- rbind(n.mean1,n.mean2,n.mean3,n.mean4, n.mean5, n.mean6)
n.sigma <- matrix(c(2.5,0,0,2.5),2,2)
# 1. Prepare a dataset
## 1.1. generate dataset
data.full = generate.mvn.mixture(p.mus, n.mus, p.sigma, n.sigma, imbalance.ratio = imbalance.ratio.s, n.samples = n.samples)
# 1. Prepare a dataset
## 1.1. generate dataset
data.full = generate.mvn.mixture(p.mus, n.mus, p.sigma, n.sigma, imbalance.ratio = imbalance.ratio.s, n.sample = n.samples)
indices.pos = (1:n.samples)[data$y == "pos"]
indices.pos = (1:n.samples)[data.full$y == "pos"]
indices.neg = (1:n.samples)[data.full$y == "neg"]
indices.pos
indices.neg
n.samples.pos.train = floor(length(indices.pos) * 0.8)
n.samples.neg.train = floor(length(indices.neg) * 0.8)
n.samples.pos.train
n.samples.neg.train
indices.pos.train = sample(indices.pos, n.samples.pos.train)
indices.neg.train = sample(indices.neg, n.samples.neg.train)
indices.train = sort(c(indices.pos.train,indices.neg.train))
data.training = data[indices.train, ]
data.testing = data[-indices.train, ]
data.training = data.full[indices.train, ]
data.testing = data.full[-indices.train, ]
data.testing
length(data.testing)
dim(data.testing)
dim(data.training)
dim(data.testing)
## 2.2 split the dataset into training set and testing set by 8:2 strafitied sampling
n.samples.pos.train = round(length(indices.pos) * 0.8)
n.samples.neg.train = round(length(indices.neg) * 0.8)
indices.pos.train = sample(indices.pos, n.samples.pos.train)
indices.neg.train = sample(indices.neg, n.samples.neg.train)
indices.train = sort(c(indices.pos.train,indices.neg.train))
data.training = data.full[indices.train, ]
data.testing = data.full[-indices.train, ]
dim(data.testing )
data.testing$y
(data.testing$y) == 'pos'
sum((data.testing$y) == 'pos')
sum((data.testing$y) == 'pos')/length(data.testing$y)
sum((data.testing$y) == 'neg')/length(data.testing$y)
sum((data.testing$y) == 'neg')/sum((data.testing$y) == 'pos')
# 1. Prepare a dataset
## 1.1. generate dataset
data.full = generate.mvn.mixture(p.mus, n.mus, p.sigma, n.sigma, imbalance.ratio = imbalance.ratio, n.sample = n.samples)
indices.pos = (1:n.samples)[data.full$y == "pos"]
indices.neg = (1:n.samples)[data.full$y == "neg"]
## 2.2 split the dataset into training set and testing set by 8:2 strafitied sampling
n.samples.pos.train = round(length(indices.pos) * 0.8)
n.samples.neg.train = round(length(indices.neg) * 0.8)
indices.pos.train = sample(indices.pos, n.samples.pos.train)
indices.neg.train = sample(indices.neg, n.samples.neg.train)
indices.train = sort(c(indices.pos.train,indices.neg.train))
data.training = data.full[indices.train, ]
data.testing = data.full[-indices.train, ]
sum((data.testing$y) == 'neg')/sum((data.testing$y) == 'pos')
sum((data.testing$y) == 'neg')/sum((data.testing$y) == 'pos')
sum((data.testing$y) == 'neg')/sum((data.testing$y) == 'pos')
# 1. Prepare a dataset
## 1.1. generate dataset
data.full = generate.mvn.mixture(p.mus, n.mus, p.sigma, n.sigma, imbalance.ratio = imbalance.ratio, n.sample = n.samples)
indices.pos = (1:n.samples)[data.full$y == "pos"]
indices.neg = (1:n.samples)[data.full$y == "neg"]
length(indices.neg) / length(indices.pos)
## 2.2 split the dataset into training set and testing set by 8:2 strafitied sampling
n.samples.pos.train = round(length(indices.pos) * 0.8)
n.samples.neg.train = round(length(indices.neg) * 0.8)
indices.pos.train = sample(indices.pos, n.samples.pos.train)
indices.neg.train = sample(indices.neg, n.samples.neg.train)
indices.train = sort(c(indices.pos.train,indices.neg.train))
data.training = data.full[indices.train, ]
data.testing = data.full[-indices.train, ]
length(indices.neg) / length(indices.pos)
length(data.training$y)
sum((data.training$y) == 'neg')/sum((data.training$y) == 'pos')
sum((data.training$y) == 'neg')/sum((data.training$y) == 'pos')
length(data.testing$y)
sum((data.testing$y) == 'neg')/sum((data.testing$y) == 'pos')
data.full = generate.mvn.mixture(p.mus, n.mus, p.sigma, n.sigma, imbalance.ratio = imbalance.ratio, n.sample = n.samples)
indices.pos = (1:n.samples)[data.full$y == "pos"]
indices.neg = (1:n.samples)[data.full$y == "neg"]
## 2.2 split the dataset into training set and testing set by 8:2 strafitied sampling
n.samples.pos.train = round(length(indices.pos) * 0.8)
n.samples.neg.train = round(length(indices.neg) * 0.8)
indices.pos.train = sample(indices.pos, n.samples.pos.train)
indices.neg.train = sample(indices.neg, n.samples.neg.train)
indices.train = sort(c(indices.pos.train,indices.neg.train))
data.training = data.full[indices.train, ]
data.testing = data.full[-indices.train, ]
length(indices.neg) / length(indices.pos)
length(data.training$y)
sum((data.training$y) == 'neg')/sum((data.training$y) == 'pos')
length(data.testing$y)
sum((data.testing$y) == 'neg')/sum((data.testing$y) == 'pos')
data.full = generate.mvn.mixture(p.mus, n.mus, p.sigma, n.sigma, imbalance.ratio = imbalance.ratio, n.sample = n.samples)
indices.pos = (1:n.samples)[data.full$y == "pos"]
indices.neg = (1:n.samples)[data.full$y == "neg"]
## 2.2 split the dataset into training set and testing set by 8:2 strafitied sampling
n.samples.pos.train = round(length(indices.pos) * 0.8)
n.samples.neg.train = round(length(indices.neg) * 0.8)
indices.pos.train = sample(indices.pos, n.samples.pos.train)
indices.neg.train = sample(indices.neg, n.samples.neg.train)
indices.train = sort(c(indices.pos.train,indices.neg.train))
data.training = data.full[indices.train, ]
data.testing = data.full[-indices.train, ]
length(indices.neg) / length(indices.pos)
length(data.training$y)
sum((data.training$y) == 'neg')/sum((data.training$y) == 'pos')
length(data.testing$y)
sum((data.testing$y) == 'neg')/sum((data.testing$y) == 'pos')
data.full = generate.mvn.mixture(p.mus, n.mus, p.sigma, n.sigma, imbalance.ratio = imbalance.ratio, n.sample = n.samples)
indices.pos = (1:n.samples)[data.full$y == "pos"]
indices.neg = (1:n.samples)[data.full$y == "neg"]
## 2.2 split the dataset into training set and testing set by 8:2 strafitied sampling
n.samples.pos.train = round(length(indices.pos) * 0.8)
n.samples.neg.train = round(length(indices.neg) * 0.8)
indices.pos.train = sample(indices.pos, n.samples.pos.train)
indices.neg.train = sample(indices.neg, n.samples.neg.train)
indices.train = sort(c(indices.pos.train,indices.neg.train))
data.training = data.full[indices.train, ]
data.testing = data.full[-indices.train, ]
length(indices.neg) / length(indices.pos)
length(data.training$y)
sum((data.training$y) == 'neg')/sum((data.training$y) == 'pos')
length(data.testing$y)
sum((data.testing$y) == 'neg')/sum((data.testing$y) == 'pos')
data.full = generate.mvn.mixture(p.mus, n.mus, p.sigma, n.sigma, imbalance.ratio = imbalance.ratio, n.sample = n.samples)
indices.pos = (1:n.samples)[data.full$y == "pos"]
indices.neg = (1:n.samples)[data.full$y == "neg"]
## 2.2 split the dataset into training set and testing set by 8:2 strafitied sampling
n.samples.pos.train = round(length(indices.pos) * 0.8)
n.samples.neg.train = round(length(indices.neg) * 0.8)
indices.pos.train = sample(indices.pos, n.samples.pos.train)
indices.neg.train = sample(indices.neg, n.samples.neg.train)
indices.train = sort(c(indices.pos.train,indices.neg.train))
data.training = data.full[indices.train, ]
data.testing = data.full[-indices.train, ]
length(indices.neg) / length(indices.pos)
length(data.training$y)
sum((data.training$y) == 'neg')/sum((data.training$y) == 'pos')
length(data.testing$y)
sum((data.testing$y) == 'neg')/sum((data.testing$y) == 'pos')
data.full = generate.mvn.mixture(p.mus, n.mus, p.sigma, n.sigma, imbalance.ratio = imbalance.ratio, n.sample = n.samples)
indices.pos = (1:n.samples)[data.full$y == "pos"]
indices.neg = (1:n.samples)[data.full$y == "neg"]
## 2.2 split the dataset into training set and testing set by 8:2 strafitied sampling
n.samples.pos.train = round(length(indices.pos) * 0.8)
n.samples.neg.train = round(length(indices.neg) * 0.8)
indices.pos.train = sample(indices.pos, n.samples.pos.train)
indices.neg.train = sample(indices.neg, n.samples.neg.train)
indices.train = sort(c(indices.pos.train,indices.neg.train))
data.training = data.full[indices.train, ]
data.testing = data.full[-indices.train, ]
length(indices.neg) / length(indices.pos)
length(data.training$y)
sum((data.training$y) == 'neg')/sum((data.training$y) == 'pos')
length(data.testing$y)
sum((data.testing$y) == 'neg')/sum((data.testing$y) == 'pos')
# 2. GS-WSVM
data.gswsvm = data.training
indices.data.gswsvm.pos = (1:n.samples)[data.gswsvm$y == "pos"]
indices.data.gswsvm.neg = (1:n.samples)[data.gswsvm$y == "neg"]
library(mclust)
install.packages("mclust")
install.packages("mclust")
library(mclust)
#cost ratio
c.neg = 4
c.pos = 1
cost.ratio = c.neg/c.pos
#real imbalance ratio
imbalance.ratio = 4
pi.pos = 1/(1+imbalance.ratio)
pi.neg = 1 - pi.pos
#sampling imbalance ratio
pi.s.pos = 0.3
pi.s.neg = 1 - pi.s.pos
imbalance.ratio.s =  pi.s.neg / pi.s.pos
L.pos = c.neg * pi.s.neg * pi.pos
L.neg = c.pos * pi.s.pos * pi.neg
#data generation
n.samples = 1e4
#checkerboard data
p.mean1 <- c(-7,-5);
p.mean2 <- c(3,-5);
p.mean3 <- c(-2,0);
p.mean4 <- c(8,0);
p.mean5 <- c(-7,5);
p.mean6 <- c(2,5);
p.mus <- rbind(p.mean1, p.mean2, p.mean3, p.mean4, p.mean5, p.mean6)
p.sigma <- matrix(c(2,0,0,2),2,2)
n.mean1 <- c(-2,-5);
n.mean2 <- c(8,-5);
n.mean3 <- c(-7,0);
n.mean4 <- c(3,0);
n.mean5 <- c(-2,5);
n.mean6 <- c(8,5);
n.mus <- rbind(n.mean1,n.mean2,n.mean3,n.mean4, n.mean5, n.mean6)
n.sigma <- matrix(c(2.5,0,0,2.5),2,2)
c.set = 2^(-5 : 5);
gamma.set = 2^(-5 : 5);
# 1. Prepare a dataset
## 1.1. generate dataset
data.full = generate.mvn.mixture(p.mus, n.mus, p.sigma, n.sigma, imbalance.ratio = imbalance.ratio, n.sample = n.samples)
indices.pos = (1:n.samples)[data.full$y == "pos"]
indices.neg = (1:n.samples)[data.full$y == "neg"]
## 1.2 split the dataset into training set and testing set by 8:2 strafitied sampling
n.samples.pos.train = round(length(indices.pos) * 0.8)
n.samples.neg.train = round(length(indices.neg) * 0.8)
indices.pos.train = sample(indices.pos, n.samples.pos.train)
indices.neg.train = sample(indices.neg, n.samples.neg.train)
indices.train = sort(c(indices.pos.train,indices.neg.train))
data.training = data.full[indices.train, ]
data.testing = data.full[-indices.train, ]
# 2.1 Apply gmc-smote
data.gswsvm <- data.training
data.gswsvm.pos <- data.gswsvm[data.gswsvm$y == 'pos']
data.gswsvm.pos <- data.gswsvm[data.gswsvm$y == 'pos',]
data.gswsvm.pos
data.gswsvm.pos$y
data.gswsvm.pos$y == 'neg'
sum(data.gswsvm.pos$y == 'neg')
# 2.1 Apply gmc-smote
data.gswsvm <- data.training
data.gswsvm.pos <- data.gswsvm[data.gswsvm$y == 'pos',]
data.gswsvm.neg <- data.gswsvm[data.gswsvm$y == 'neg',]
data.gswsvm.neg
data.gswsvm.neg[-y]
data.gswsvm.neg[-'y']
data.gswsvm.neg
type(data.gswsvm.neg)
summary(data.gswsvm.neg)
str(data.gswsvm.neg)
data.gswsvm.neg[-3]
gmc.model.pos <- Mclust(data.gswsvm.pos[,-3])
G <- gmc.model.posl$G;
G <- gmc.model.pos$G;
d <- gmc.model.pos$d;
prob <- gmc.model.pos$parameters$pro
means <- gmc.model.pos$parameters$mean
vars <- gmc.model.pos$parameters$variance$sigma
length(data.gswsvm.pos$y)
oversample.ratio = (pi.s.pos / pi.pos) - 1
n.oversample = round(length(data.gswsvm.pos$y) * oversample.ratio)
prob
plot(prob)
plot(prob, ylim = [0,1])
plot(prob, ylim = c(0,1)
)
d
gmc.index <- sample(x = 1:G, size = n.oversample, replace = T, prob = prob)
gmc.train.x = matrix(0, n.oversample, d)
gmc.train.x
G <- gmc.model.pos$G;
d <- gmc.model.pos$d;
prob <- gmc.model.pos$parameters$pro
means <- gmc.model.pos$parameters$mean
vars <- gmc.model.pos$parameters$variance$sigma
n.oversample <- round(length(data.gswsvm.pos$y) * oversample.ratio)
gmc.index <- sample(x = 1:G, size = n.oversample, replace = T, prob = prob)
gmc.train.x <- matrix(0, n.oversample, d)
for(i in 1 : n.oversample) {
gmc.train.x[i,] <- rmvnorm(1, mean = means[ , gmc.index[i]],sigma=vars[,,gmc.index[i]])
}
gmc.index <- sample(x = 1:G, size = n.oversample, replace = T, prob = prob)
gmc.train.x <- matrix(0, n.oversample, d)
for(i in 1 : n.oversample) {
gmc.train.x[i,] <- rmvnorm(1, mean = means[ , gmc.index[i]],sigma=vars[,,gmc.index[i]])
}
library(mvtnorm)
for(i in 1 : n.oversample) {
gmc.train.x[i,] <- rmvnorm(1, mean = means[ , gmc.index[i]],sigma=vars[,,gmc.index[i]])
}
data.gswsvm.train.x <- rbind(gmc.train.x, data.gswsvm[-3])
data.gswsvm[-3]
head(data.gswsvm[-3])
gmc.train.x
head(gmc.train.x)
data.gswsvm.train.y <- c(gmc.train.y, data.gsvm$y)
data.gswsvm.train.y <- c(rep("pos", n.oversample), data.gsvm$y)
data.gswsvm.train.y <- c(rep("pos", n.oversample), data.gswsvm$y)
data.gswsvm.train.x <- rbind(gmc.train.x, data.gswsvm[-3])
data.gswsvm.train.x <- rbind(gmc.train.x, as.matrix(data.gswsvm[-3]))
as.matrix(data.gswsvm[-3])
head(as.matrix(data.gswsvm[-3]))
data.gswsvm.train.x <- rbind(gmc.train.x, as.matrix(data.gswsvm[-3]))
data.gswsvm.train.y <- c(rep("pos", n.oversample), data.gswsvm$y)
data.gswsvm.train <- data.frame(data.gswsvm.train.x, data.gswsvm.train.y)
colnames(data.gswsvm.train) <- c("x1","x2","y")
data.gswsvm.train
head(data.gswsvm.train)
index(data.gswsvm.train)
gmc.train.x
head(gmc.train.x)
head(data.gswsvm.train)
tail(data.gswsvm.train)
head(gmc.train.x)
data.gswsvm.train.y
data.gswsvm$y
rep("pos", n.oversample)
rep("pos", n.oversample)
data.gswsvm$y
values(data.gswsvm$y)
as.vector(data.gswsvm$y)
data.gswsvm.train.y <- c(rep("pos", n.oversample), as.vector(data.gswsvm$y))
data.gswsvm.train <- data.frame(data.gswsvm.train.x, data.gswsvm.train.y)
colnames(data.gswsvm.train) <- c("x1","x2","y")
as.vector(data.gswsvm$y)
data.gswsvm.train
tail(data.gswsvm.train)
data.gswsvm.train$y
str(data.gswsvm.train$y)
data.gswsvm.train.y <- factor(data.gswsvm.train.y, levels = c("neg", "pos"))
data.gswsvm.train.x <- rbind(gmc.train.x, as.matrix(data.gswsvm[-3]))
data.gswsvm.train.y <- c(rep("pos", n.oversample), as.vector(data.gswsvm$y))
data.gswsvm.train.y <- factor(data.gswsvm.train.y, levels = c("neg", "pos"))
data.gswsvm.train <- data.frame(data.gswsvm.train.x, data.gswsvm.train.y)
colnames(data.gswsvm.train) <- c("x1","x2","y")
data.gswsvm.train
data.gswsvm.train$y
sum(data.gswsvm.train$y=='pos')
n.oversample
dim(data.gswsvm.pos)
